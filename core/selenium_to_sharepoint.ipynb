{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8d3619-2c10-475e-83c2-2ea8c413de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a9f4f9-edf8-4fff-bb9a-543933205d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from msal import PublicClientApplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "644e7646-58a0-4408-9e7c-e7a3e7fbc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.dirname('__file__'), 'scripts'))\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), 'configs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364b6bca-2f4e-4de2-86c0-5c985ac00bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.secrets import *\n",
    "from scripts.auth import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df06ff91-ab5c-4d0b-bd50-3d6f5b2a072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_APP_ID = 52\n",
    "TRACKVIA_TABLE_ID = 804\n",
    "TRACKVIA_VIEW_ID = 2323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddc5fdb-9d66-4990-99f4-0a6c545d19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = TRACKVIA_USERNAME\n",
    "PASSWORD = TRACKVIA_PASSWORD\n",
    "LOGIN_URL = TRACKVIA_LOGIN_URL\n",
    "\n",
    "GRID_URL = f\"https://{TENANT}.trackvia.com/#/apps/{TRACK_APP_ID}/tables/{TRACKVIA_TABLE_ID}/views/{TRACKVIA_VIEW_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ba6722-8665-4103-aabe-710710456aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = AZ_CLIENT_ID\n",
    "CLIENT_SECRET =  AZ_CLIENT_SECRET\n",
    "AUTHORITY_URL = AZ_AUTHORITY_URL\n",
    "SCOPES = AZ_SCOPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be8b3cf6-26dc-49ec-af08-3d83f1088c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAREPOINT_FOLDER = \"/PowerBI Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4a3366-56ab-4f17-841d-0c43b9294fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAREPOINT_URL = SHAREPOINT_URL\n",
    "SHAREPOINT_USERNAME = SHAREPOINT_USERNAME\n",
    "SHAREPOINT_PASSWORD = SHAREPOINT_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c7cd0db-14fc-4eec-9820-af7be2d4dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token_v1():\n",
    "    app = PublicClientApplication(CLIENT_ID, authority=AUTHORITY_URL)\n",
    "    result = app.acquire_token_by_username_password(USERNAME, SHAREPOINT_PASSWORD, scopes=SCOPES)\n",
    "    if \"access_token\" in result:\n",
    "        return result[\"access_token\"]\n",
    "    else:\n",
    "        print(result.get(\"error_description\"))\n",
    "        raise Exception(\"Failed to acquire token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "047f303a-bccc-486d-88aa-e547d30fa090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token_v2():\n",
    "    app = PublicClientApplication(CLIENT_ID, authority=AUTHORITY_URL)\n",
    "    flow = app.initiate_device_flow(scopes=SCOPES)\n",
    "    if \"user_code\" in flow:\n",
    "        print(f\"Go to {flow['verification_uri']} and enter the code: {flow['user_code']}\")\n",
    "        result = app.acquire_token_by_device_flow(flow)\n",
    "        if \"access_token\" in result:\n",
    "            return result[\"access_token\"]\n",
    "        else:\n",
    "            print(result.get(\"error_description\"))\n",
    "            raise Exception(\"Failed to acquire token\")\n",
    "    else:\n",
    "        raise Exception(\"Failed to initiate device flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf99f9a4-dc9d-4544-9a52-7981a154656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b6bedc-da76-4bd9-b7ee-3a7296291f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a44b1234-e667-46d7-b914-8e2597ae40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful.\n"
     ]
    }
   ],
   "source": [
    "login_to_trackvia(driver=driver, login_url=LOGIN_URL, username=USERNAME, password=PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6bc9eac-65e3-4dba-949e-ff511a5a6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For admin to Give Consent\n",
    "#redirect_uri = \"https://login.microsoftonline.com/common/oauth2/nativeclient\"\n",
    "#f\"https://login.microsoftonline.com/{AZ_TENANT_ID}/adminconsent?client_id={AZ_CLIENT_ID}&redirect_uri={redirect_uri}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "108cd55a-a8bd-4199-8b51-7324b491dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UN-Comment the following lines to trigger the MFA flow\n",
    "#access_token = get_access_token_v2()\n",
    "#ctx = ClientContext(SHAREPOINT_URL).with_access_token(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "453591af-cb7c-404c-b1a6-3831c265dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_name():\n",
    "        # Step 3: Extract the table name from the <h3> tag\n",
    "    table_name_element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-qa-id='view-title-menu'] h3\"))\n",
    "    )\n",
    "    table_name_text = table_name_element.text.strip()\n",
    "\n",
    "    # Extract the text within the square brackets []\n",
    "    table_name_match = re.search(r\"\\[(.*?)\\]\", table_name_text)\n",
    "    table_name = table_name_match.group(1) if table_name_match else \"data_table\"\n",
    "\n",
    "    print(f\"Extracted Table Name: {table_name}\")\n",
    "\n",
    "    return table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b17f5af-8936-4bf9-ac33-fd5d2c83b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_pages():\n",
    "        # Extract the total number of pages dynamically\n",
    "    total_pages_element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-qa-id='page-navigator__viewing-page'] strong\"))\n",
    "    )\n",
    "    total_pages = int(total_pages_element.text.strip())\n",
    "    print(f\"Total Pages: {total_pages}\")\n",
    "\n",
    "    return total_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f6ca777-50e7-45d9-afbb-fb190f60808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers(headers=None):\n",
    "    if headers is None:\n",
    "        headers = []\n",
    "        header_elements = soup.find_all(\"div\", class_=\"GridHeaderCell\")\n",
    "        for header in header_elements:\n",
    "            header_title = header.find(\"span\", class_=\"GridHeaderCell__inner__title\")\n",
    "            if header_title:\n",
    "                headers.append(header_title.text.strip())\n",
    "        #print(\"Extracted Headers:\", headers)\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef80d326-0744-4427-a5bb-1ca128d9313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Table Name: Partners\n",
      "Total Pages: 2\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Data saved to partners_data.csv\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    driver.get(GRID_URL)\n",
    "    time.sleep(5) \n",
    "\n",
    "    table_name = get_table_name()\n",
    "\n",
    "    all_rows = []\n",
    "    headers = None\n",
    "\n",
    "    total_pages = get_total_pages()\n",
    "\n",
    "    for page_num in range(1, total_pages + 1):\n",
    "        print(f\"Scraping page {page_num}...\")\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Parse the page source with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Extract headers (only once on the first page)\n",
    "\n",
    "        headers = get_headers(headers=headers)\n",
    "\n",
    "        # Extract rows from GridBody__docked and GridBody__scrollable\n",
    "        grid_body_docked = soup.find(\"div\", class_=\"GridBody__docked\")\n",
    "        grid_body_scrollable = soup.find(\"div\", class_=\"GridBody__scrollable\")\n",
    "\n",
    "        if grid_body_docked and grid_body_scrollable:\n",
    "            docked_rows = grid_body_docked.find_all(\"div\", class_=\"GridBodyRow\")\n",
    "            scrollable_rows = grid_body_scrollable.find_all(\"div\", class_=\"GridBodyRow\")\n",
    "\n",
    "            for docked_row, scrollable_row in zip(docked_rows, scrollable_rows):\n",
    "                # Extract data from docked row cells\n",
    "                docked_cells = docked_row.find_all(\"div\", class_=\"GridBodyCell\")\n",
    "                docked_data = []\n",
    "                for cell in docked_cells:\n",
    "                    cell_inner = cell.find(\"div\", class_=\"GridBodyCell__inner\")\n",
    "                    if cell_inner:\n",
    "                        link = cell_inner.find(\"a\")\n",
    "                        docked_data.append(link.text.strip() if link else cell_inner.text.strip())\n",
    "                    else:\n",
    "                        docked_data.append(\"\")\n",
    "\n",
    "                # Extract data from scrollable row cells\n",
    "                scrollable_cells = scrollable_row.find_all(\"div\", class_=\"GridBodyCell\")\n",
    "                scrollable_data = []\n",
    "                for cell in scrollable_cells:\n",
    "                    cell_inner = cell.find(\"div\", class_=\"GridBodyCell__inner\")\n",
    "                    scrollable_data.append(cell_inner.text.strip() if cell_inner else \"\")\n",
    "\n",
    "                # Combine data from both docked and scrollable parts\n",
    "                combined_data = docked_data + scrollable_data\n",
    "\n",
    "                # Remove the first empty element and the last duplicate element\n",
    "                cleaned_data = combined_data[1:-1]\n",
    "\n",
    "                all_rows.append(cleaned_data)\n",
    "\n",
    "        # Click the \"Next Page\" button if it's not the last page\n",
    "        if page_num < total_pages:\n",
    "            next_button = driver.find_element(By.CSS_SELECTOR, \"button.next-page\")\n",
    "            next_button.click()\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(all_rows, columns=headers[:len(all_rows[0])])\n",
    "\n",
    "    # Save the DataFrame with the table name\n",
    "    output_file = f\"{table_name.replace(' ', '_').lower()}_data.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "    # if the MFA seucceed above, un-comment to uplaod to the SharePoint\n",
    "    \n",
    "    #with open(output_file, \"rb\") as file_content:\n",
    "    #    target_folder = ctx.web.get_folder_by_server_relative_url(SHAREPOINT_FOLDER)\n",
    "    #    target_file = target_folder.upload_file(os.path.basename(output_file), file_content).execute_query()\n",
    "    #    print(f\"File uploaded to SharePoint: {target_file.serverRelativeUrl}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5f019-b84a-4e18-86a5-d13a634c74f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96a9f5-c4af-4d6f-83fb-c76a60927d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
